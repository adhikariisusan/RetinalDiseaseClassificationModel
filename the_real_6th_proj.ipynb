{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e430a481-23a9-4a29-b98d-260aa674aa86",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 3135,
    "lastExecutedAt": 1748374421146,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "!pip install kagglehub\n\n",
    "outputsMetadata": {
     "0": {
      "height": 290,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (25.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: kagglehub in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (24.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->kagglehub) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install kagglehub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38c1b6fc-17b8-4dd5-b2af-ef4fdd91cb2e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 1352,
    "lastExecutedAt": 1748374422500,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"andrewmvd/retinal-disease-classification\")\n\nprint(\"Path to dataset files:\", path)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 38,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\adhik\\.cache\\kagglehub\\datasets\\andrewmvd\\retinal-disease-classification\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"andrewmvd/retinal-disease-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6fdc5-2e85-4f70-a302-c71d4b452c51",
   "metadata": {
    "id": "o9Q1QujFtrYl"
   },
   "source": [
    "Here we have successfully imported the dataset for retinal disease detection system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e10f2f-c7c5-46d2-80fe-bf1238bb8cd4",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 45,
    "id": "bA0sGTmgtxjJ",
    "lastExecutedAt": 1748374422545,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport numpy as np\nimport os\nfrom PIL import Image\n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb965ed2-ba88-4e10-abb7-5e723fa927ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionCancelledAt": null,
    "executionTime": 61,
    "id": "dVnITkAAvFtG",
    "lastExecutedAt": 1748374422606,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Let us observe the training data\neye_disease_train = pd.read_csv(path + '/Training_Set/Training_Set/RFMiD_Training_Labels.csv')\neye_disease_train.head()",
    "outputId": "0c988675-0b57-4cf3-d81a-efc8c8d6af61",
    "outputsMetadata": {
     "0": {
      "height": 262,
      "tableState": {},
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  ...  CME  PTCR  \\\n",
       "0   1             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "1   2             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "2   3             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "3   4             1   0     0   1   0    0     0     0    0  ...    0     0   \n",
       "4   5             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "\n",
       "   CF  VH  MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "0   0   0    0   0     0    0     0   0  \n",
       "1   0   0    0   0     0    0     0   0  \n",
       "2   0   0    0   0     0    0     0   0  \n",
       "3   0   0    0   0     0    0     0   0  \n",
       "4   0   0    0   0     0    0     0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us observe the training data\n",
    "eye_disease_train = pd.read_csv(path + '/Training_Set/Training_Set/RFMiD_Training_Labels.csv')\n",
    "eye_disease_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd577df-37a0-41c8-a617-6c313d5d0fad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionCancelledAt": null,
    "executionTime": 49,
    "id": "eoFZY_2LvXti",
    "lastExecutedAt": 1748374422655,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "\nprint(\"The Columns of the Training Data are \"+str(eye_disease_train.columns))\nprint(\"The Shape of the Training Data is\"+str(eye_disease_train.shape))",
    "outputId": "444ca970-cc46-40b4-d812-6652aa394947",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Columns of the Training Data are Index(['ID', 'Disease_Risk', 'DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n",
      "       'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH', 'ODP', 'ODE', 'ST',\n",
      "       'AION', 'PT', 'RT', 'RS', 'CRS', 'EDN', 'RPEC', 'MHL', 'RP', 'CWS',\n",
      "       'CB', 'ODPM', 'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n",
      "       'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL'],\n",
      "      dtype='object')\n",
      "The Shape of the Training Data is(1920, 47)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The Columns of the Training Data are \"+str(eye_disease_train.columns))\n",
    "print(\"The Shape of the Training Data is\"+str(eye_disease_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72992f09-ad56-4311-b76e-27f00334d4b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionCancelledAt": null,
    "executionTime": 54,
    "id": "D_KfmoH4y--S",
    "lastExecutedAt": 1748374422709,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "eye_disease_test = pd.read_csv(path + '/Test_Set/Test_Set/RFMiD_Testing_Labels.csv')\neye_disease_test.head()\n\n",
    "outputId": "e1e833c8-7c02-4923-dda2-7190867cdc5e",
    "outputsMetadata": {
     "0": {
      "height": 262,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "18331351-830e-41fd-8bfa-62b91d85f53a",
        "nodeType": "const"
       }
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  ...  CME  PTCR  \\\n",
       "0   1             1   1     0   0   0    0     0     1    0  ...    0     0   \n",
       "1   2             1   1     0   0   0    0     1     0    0  ...    0     0   \n",
       "2   3             1   1     0   0   0    0     0     0    0  ...    0     0   \n",
       "3   4             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "4   5             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "\n",
       "   CF  VH  MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "0   0   0    0   0     0    0     0   0  \n",
       "1   0   0    0   0     0    0     0   0  \n",
       "2   0   0    0   0     0    0     0   0  \n",
       "3   0   0    0   0     0    0     0   0  \n",
       "4   0   0    0   0     0    0     0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_disease_test = pd.read_csv(path + '/Test_Set/Test_Set/RFMiD_Testing_Labels.csv')\n",
    "eye_disease_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153624e-8e75-4736-b787-4401f94337b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionCancelledAt": null,
    "executionTime": 49,
    "id": "zQYfWP6bzW44",
    "lastExecutedAt": 1748374422758,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(\"The Columns of the Testing Data are \"+str(eye_disease_test.columns))\nprint(\"The Shape of the Testing Data is\"+str(eye_disease_test.shape))",
    "outputId": "2e82b39d-a95f-4a1c-e522-3acca40571f6",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Columns of the Testing Data are Index(['ID', 'Disease_Risk', 'DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n",
      "       'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH', 'ODP', 'ODE', 'ST',\n",
      "       'AION', 'PT', 'RT', 'RS', 'CRS', 'EDN', 'RPEC', 'MHL', 'RP', 'CWS',\n",
      "       'CB', 'ODPM', 'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n",
      "       'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL'],\n",
      "      dtype='object')\n",
      "The Shape of the Testing Data is(640, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"The Columns of the Testing Data are \"+str(eye_disease_test.columns))\n",
    "print(\"The Shape of the Testing Data is\"+str(eye_disease_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c411b7-959d-42dc-8ff9-6524e6cc75f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionCancelledAt": null,
    "executionTime": 52,
    "id": "N-KAEM6JzksQ",
    "lastExecutedAt": 1748374422810,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "eye_disease_eval = pd.read_csv(path + '/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv')\neye_disease_eval.head()",
    "outputId": "87c2b633-854a-41cb-8bd7-512dbbd6791c",
    "outputsMetadata": {
     "0": {
      "height": 262,
      "tableState": {
       "customFilter": {
        "const": {
         "type": "boolean",
         "valid": true,
         "value": true
        },
        "id": "18331351-830e-41fd-8bfa-62b91d85f53a",
        "nodeType": "const"
       }
      },
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Disease_Risk</th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Disease_Risk  DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  ...  CME  PTCR  \\\n",
       "0   1             1   1     0   0   0    0     0     1    0  ...    0     0   \n",
       "1   2             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "2   3             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "3   4             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "4   5             1   0     0   0   0    0     0     0    0  ...    0     0   \n",
       "\n",
       "   CF  VH  MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "0   0   0    0   0     0    0     0   0  \n",
       "1   0   0    0   0     0    0     0   0  \n",
       "2   0   0    0   0     0    0     0   0  \n",
       "3   0   0    0   0     0    0     0   0  \n",
       "4   0   0    0   0     0    0     0   0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_disease_eval = pd.read_csv(path + '/Evaluation_Set/Evaluation_Set/RFMiD_Validation_Labels.csv')\n",
    "eye_disease_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024e588-437f-432d-afb1-3f9b2e8b24bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionCancelledAt": null,
    "executionTime": 53,
    "id": "XkMyujjfzvLk",
    "lastExecutedAt": 1748374422863,
    "lastExecutedByKernel": "e7d2420a-e1e1-4f1b-88ca-d2e298265e26",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(\"The Columns of the Evaluation Data are \"+str(eye_disease_eval.columns))\nprint(\"The Shape of the Evaluation Data is\" +str(eye_disease_eval.shape))",
    "outputId": "b340ccaf-6bf0-4ee8-93b4-c68b7ab56108",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Columns of the Evaluation Data are Index(['ID', 'Disease_Risk', 'DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN',\n",
      "       'ERM', 'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH', 'ODP', 'ODE', 'ST',\n",
      "       'AION', 'PT', 'RT', 'RS', 'CRS', 'EDN', 'RPEC', 'MHL', 'RP', 'CWS',\n",
      "       'CB', 'ODPM', 'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n",
      "       'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL'],\n",
      "      dtype='object')\n",
      "The Shape of the Evaluation Data is(640, 47)\n"
     ]
    }
   ],
   "source": [
    "print(\"The Columns of the Evaluation Data are \"+str(eye_disease_eval.columns))\n",
    "print(\"The Shape of the Evaluation Data is\" +str(eye_disease_eval.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c655773-2679-4c9e-aabf-ef1c48cb8576",
   "metadata": {
    "id": "O0oRcP5Y1fuf"
   },
   "source": [
    "---\n",
    "\n",
    "# Let us Now Observe the Training DataSet and the Corresponding Images Provided\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6980235c",
   "metadata": {},
   "source": [
    "Let us first define a function that converts the training , testing and validation dataset's images and its corresponding arrays as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac80bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_HEIGHT = 224\n",
    "TARGET_WIDTH = 224\n",
    "TARGET_CHANNELS = 3 \n",
    "def convert_img_to_np(image_directory,dataset):\n",
    "    dt_imglist = []\n",
    "    dt_labellist = []\n",
    "    dataset['ID'] = dataset['ID'].astype(int) \n",
    "    for filename in os.listdir(image_directory):\n",
    "      if filename.endswith('.png'):\n",
    "        img_id = filename[:-4]\n",
    "        #print(\"image id is\",img_id)\n",
    "        #loading the image using Pillow PIL\n",
    "        img_path = os.path.join(image_directory, filename)\n",
    "        try:\n",
    "          img = Image.open(img_path)\n",
    "          img=img.convert('RGB')\n",
    "          img = img.resize((TARGET_WIDTH, TARGET_HEIGHT)) \n",
    "          #converting the image to numpy array\n",
    "          img_array = np.array(img)\n",
    "          if img_array.shape != (TARGET_HEIGHT, TARGET_WIDTH, 3):\n",
    "            print(f\"Skipping '{filename}': Incorrect shape after resize {img_array.shape}\")\n",
    "            continue\n",
    "\n",
    "        except Exception as e:\n",
    "          print(f\"Skipping '{filename}': Error during image processing: {e}\")\n",
    "          continue\n",
    "\n",
    "        label = dataset[dataset['ID'] == int(img_id)].iloc[0, 1:].values\n",
    "\n",
    "        dt_imglist.append(img_array)\n",
    "        dt_labellist.append(label)\n",
    "    \n",
    "    shapes = [img.shape for img in dt_imglist]\n",
    "    unique_shapes = set(shapes)\n",
    "    print(\"The Unique Shapes are\"+str(unique_shapes))\n",
    "    images_np = np.array(dt_imglist, dtype=np.float32)\n",
    "    labels_np = np.array(dt_labellist, dtype=np.float32)\n",
    "    print(f\"{type(images_np)} {type(labels_np)}\")\n",
    "    return images_np, labels_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286b9de",
   "metadata": {},
   "source": [
    "The Training, Testing and Validation DataSet have already been predefined above as [ eye_disease_train, eye_disease_test, eye_disease_eval]\n",
    "Now lets create the numpy labels and create the directory path for all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b171939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Training Data ---\n",
      "The Unique Shapes are{(224, 224, 3)}\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "\n",
      "--- Loading Validation Data ---\n",
      "The Unique Shapes are{(224, 224, 3)}\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "\n",
      "--- Loading Test Data ---\n",
      "The Unique Shapes are{(224, 224, 3)}\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Loading Training Data ---\")\n",
    "train_images_dir = path + '/Training_Set/Training_Set/Training'\n",
    "train_images, train_labels = convert_img_to_np(train_images_dir, eye_disease_train)\n",
    "\n",
    "print(\"\\n--- Loading Validation Data ---\")\n",
    "validation_image_dir = path + '/Evaluation_Set/Evaluation_Set/Validation'\n",
    "validation_images, validation_labels = convert_img_to_np(validation_image_dir, eye_disease_eval)\n",
    "\n",
    "print(\"\\n--- Loading Test Data ---\")\n",
    "test_images_dir = path + '/Test_Set/Test_Set/Test'\n",
    "test_images, test_labels = convert_img_to_np(test_images_dir, eye_disease_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d3ed75",
   "metadata": {},
   "source": [
    "Let us confirm the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "587ffbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Dataset Shapes (Before Normalization) ---\n",
      "Training images shape: (1920, 224, 224, 3)\n",
      "Training labels shape: (1920, 46)\n",
      "Validation images shape: (640, 224, 224, 3)\n",
      "Validation labels shape: (640, 46)\n",
      "Test images shape: (640, 224, 224, 3)\n",
      "Test labels shape: (640, 46)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Dataset Shapes (Before Normalization) ---\")\n",
    "print(f\"Training images shape: {train_images.shape}\")\n",
    "print(f\"Training labels shape: {train_labels.shape}\")\n",
    "print(f\"Validation images shape: {validation_images.shape}\")\n",
    "print(f\"Validation labels shape: {validation_labels.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb115267",
   "metadata": {},
   "source": [
    "Now let us import the neccesary dependencies that we might require for our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d4f7c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.73.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.1.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\adhik\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbaef5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50 \n",
    "from tensorflow.keras.models import Model \n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Input # For custom head\n",
    "from tensorflow.keras.optimizers import Adam # Optimizer\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # if data augmentation is needed \n",
    "import matplotlib.pyplot as plt \n",
    "from tensorflow.keras.metrics import BinaryAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44656c12",
   "metadata": {},
   "source": [
    "for resnet50 architecture we need to normalize the data, so lets normalize all the necessary data, and ensure that they are of float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1cf305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "validation_images = validation_images / 255.0\n",
    "\n",
    "#ensuring that the data are of float32 type\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "validation_labels = validation_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbf5382",
   "metadata": {},
   "source": [
    "For now, let us observe the labels, there are effectively 45 diseases and a single column for the disease risk , let us observe by including the disease risk in the labels to be loaded in the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7c0ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disease labels (output classes) for multi-label prediction: 46\n"
     ]
    }
   ],
   "source": [
    "num_disease_labels = train_labels.shape[1]\n",
    "print(f\"Number of disease labels (output classes) for multi-label prediction: {num_disease_labels}\")\n",
    "input_shape = train_images.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae942f0c",
   "metadata": {},
   "source": [
    "Now let us load the pretrained resnet50 model , where we will exclude the top classification layer, this is because we are working with retinal image dataset and resnet50 is a pretrained model that we need to use for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a4c423b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights=\"imagenet\",\n",
    "                      include_top = False, \n",
    "                      input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ec514",
   "metadata": {},
   "source": [
    "we will freeze the base layers initially to only train the new top layers, preventing pre - trained weights from being updated \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf70b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "#custom classification head \n",
    "x= base_model.output #output of the resnet50 base\n",
    "x= Flatten()(x) #flattening output to feed dense layers\n",
    "\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x= Dropout(0.5)(x)\n",
    "x= Dense(128, activation='relu')(x)\n",
    "x= Dropout(0.5)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328919a6",
   "metadata": {},
   "source": [
    "for the output layers of the multi disease classification , first we observe num_disease_labels that corresponds to the number of columns in the train_labels, than we use sigmoid activation for multi-label classification as each label is binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f03292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Dense(num_disease_labels, activation ='sigmoid')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf3cb92",
   "metadata": {},
   "source": [
    "now before training the model we will perform neccesities like markdowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8fbd5623",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[ #explicitly defining the metrics \n",
    "                  BinaryAccuracy(name='accuracy'), \n",
    "                  tf.keras.metrics.Precision(name='precision'), \n",
    "                  tf.keras.metrics.Recall(name='recall')\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068ae319",
   "metadata": {},
   "source": [
    "**STARTING THE FIRST MODEL TRAINING**\n",
    "\n",
    "*this was our custom head*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e6425a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Initial Model Training...\n",
      "Epoch 1/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.9554 - loss: 0.1719 - precision: 0.4479 - recall: 0.3986 - val_accuracy: 0.9719 - val_loss: 0.1008 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 2/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.9634 - loss: 0.1554 - precision: 0.5724 - recall: 0.3911 - val_accuracy: 0.9719 - val_loss: 0.0998 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 3/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.9665 - loss: 0.1511 - precision: 0.6472 - recall: 0.4003 - val_accuracy: 0.9719 - val_loss: 0.0999 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 4/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 2s/step - accuracy: 0.9686 - loss: 0.1469 - precision: 0.7073 - recall: 0.4003 - val_accuracy: 0.9719 - val_loss: 0.1111 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 5/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.9709 - loss: 0.1370 - precision: 0.7381 - recall: 0.4081 - val_accuracy: 0.9719 - val_loss: 0.1092 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 6/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.9710 - loss: 0.1305 - precision: 0.7760 - recall: 0.4089 - val_accuracy: 0.9719 - val_loss: 0.1057 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 7/7\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.9716 - loss: 0.1185 - precision: 0.7665 - recall: 0.4152 - val_accuracy: 0.9719 - val_loss: 0.1053 - val_precision: 0.7906 - val_recall: 0.4220\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Initial Model Training...\")\n",
    "history_initial = model.fit(\n",
    "     train_images,\n",
    "     train_labels,\n",
    "     epochs= 7, #starting with few epochs is generally better\n",
    "     batch_size = 32,\n",
    "     validation_data= (validation_images, validation_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca2ad85",
   "metadata": {},
   "source": [
    "Let us now try to fine tune our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9577de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Fine Tuning (i.e unfreezing the base layers for our model) .........\n",
      "Epoch 1/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 2s/step - accuracy: 0.9701 - loss: 0.1191 - precision: 0.7422 - recall: 0.4225 - val_accuracy: 0.9719 - val_loss: 0.1048 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 2/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 3s/step - accuracy: 0.9716 - loss: 0.1136 - precision: 0.7590 - recall: 0.4185 - val_accuracy: 0.9719 - val_loss: 0.1071 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 3/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 3s/step - accuracy: 0.9717 - loss: 0.1133 - precision: 0.7874 - recall: 0.4240 - val_accuracy: 0.9719 - val_loss: 0.1112 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 4/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - accuracy: 0.9714 - loss: 0.1159 - precision: 0.7929 - recall: 0.4190 - val_accuracy: 0.9719 - val_loss: 0.1182 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 5/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 3s/step - accuracy: 0.9714 - loss: 0.1154 - precision: 0.7774 - recall: 0.4192 - val_accuracy: 0.9719 - val_loss: 0.1115 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 6/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m176s\u001b[0m 3s/step - accuracy: 0.9716 - loss: 0.1159 - precision: 0.7868 - recall: 0.4181 - val_accuracy: 0.9719 - val_loss: 0.1088 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 7/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 3s/step - accuracy: 0.9719 - loss: 0.1129 - precision: 0.7803 - recall: 0.4219 - val_accuracy: 0.9719 - val_loss: 0.1082 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 8/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 3s/step - accuracy: 0.9718 - loss: 0.1148 - precision: 0.7927 - recall: 0.4226 - val_accuracy: 0.9719 - val_loss: 0.1029 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 9/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m754s\u001b[0m 13s/step - accuracy: 0.9717 - loss: 0.1152 - precision: 0.7867 - recall: 0.4180 - val_accuracy: 0.9719 - val_loss: 0.1015 - val_precision: 0.7906 - val_recall: 0.4220\n",
      "Epoch 10/10\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 3s/step - accuracy: 0.9717 - loss: 0.1150 - precision: 0.7974 - recall: 0.4203 - val_accuracy: 0.9719 - val_loss: 0.0998 - val_precision: 0.7906 - val_recall: 0.4220\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Fine Tuning (i.e unfreezing the base layers for our model) .........\")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    if layer.name.startswith('conv5_block'): #similar to unfreezing the last major block of resnet50\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False #keeping ealier layers frozen\n",
    "\n",
    "#now we can recompule with a very slow learning rate (IMP)\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[\n",
    "                  BinaryAccuracy(name='accuracy'), \n",
    "                  tf.keras.metrics.Precision(name='precision'), \n",
    "                  tf.keras.metrics.Recall(name='recall')\n",
    "              ])\n",
    "\n",
    "#here now we continue training for more epochs\n",
    "history_finetune = model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs = 10,\n",
    "    batch_size = 32,\n",
    "    validation_data = (validation_images, validation_labels )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a7acbb",
   "metadata": {},
   "source": [
    "Now, lets try to evaluate models final performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31759391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating final model on the test set...\n",
      "20/20 - 26s - 1s/step - accuracy: 0.9727 - loss: 0.0964 - precision: 0.7906 - recall: 0.4306\n",
      "Test Loss: 0.0964\n",
      "Test Accuracy: 0.9727\n",
      "Test Precision: 0.7906\n",
      "Test Recall: 0.4306\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating final model on the test set...\")\n",
    "loss, accuracy, precision, recall = model.evaluate(test_images, test_labels, verbose=2)\n",
    "print(f\"Test Loss: {loss:.4f}\")\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
